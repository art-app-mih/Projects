{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ФИНАЛЬНОЕ ЗАДАНИЕ: предсказание победителя в онлайн-игре"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Автор: Аппалонов Артем"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Введение\n",
    "Dota 2 — многопользовательская компьютерная игра жанра MOBA. Игроки играют между собой матчи. В каждом матче, как правило, участвует 10 человек. Матчи формируются из живой очереди, с учётом уровня игры всех игроков. Перед началом игры игроки автоматически разделяются на две команды по пять человек. Одна команда играет за светлую сторону (The Radiant), другая — за тёмную (The Dire). Цель каждой команды — уничтожить главное здание базы противника, трон. Существуют разные режимы игры, мы будем рассматривать режим Captain's Mode, в формате которого происходит большая часть киберспортивных мероприятий по Dota 2.\n",
    "\n",
    "Необходимо построить модель, которая по данным о первых пяти минутах матча будет предсказывать его исход — то есть определять команду-победителя."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Библиотеки\n",
    "\n",
    "В начале задания пропишем все библиотеки, которые могут потребоваться нам для решения задач."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "from random import sample\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Чтение файла с признаками и целями\n",
    "\n",
    "Прочитаем файл с данными features.csv и разделим его на две части: признаковое описание и целевые переменные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv('./features.csv', index_col='match_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим выборку на наличие пропусков с помощью функции count(), которая для каждого столбца показывает число заполненных значений. И занесем данный список в переменную С, а затем посчитаем количество пропущенных данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество столбцов, в которых пропущены данные: \n",
      " 12\n",
      "Признаки, в которых имеются пропуски в данных:\n",
      "first_blood_time               77677\n",
      "first_blood_team               77677\n",
      "first_blood_player1            77677\n",
      "first_blood_player2            53243\n",
      "radiant_bottle_time            81539\n",
      "radiant_courier_time           96538\n",
      "radiant_flying_courier_time    69751\n",
      "radiant_first_ward_time        95394\n",
      "dire_bottle_time               81087\n",
      "dire_courier_time              96554\n",
      "dire_flying_courier_time       71132\n",
      "dire_first_ward_time           95404\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "С = features.count()\n",
    "lose = С[С < 97230]\n",
    "print('Количество столбцов, в которых пропущены данные:','\\n',len(lose))\n",
    "print('Признаки, в которых имеются пропуски в данных:')\n",
    "print(lose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пропуски в столбцах first_blood_player1/player2 связаны с тем, что к событию \"первая кровь\" (то есть первое убийство персонажа игрока противника) могут быть причастны не все игроки, пропуски же в столбцах radiant_bottle_time\\courier_time связаны с тем, что игроки не успели за первые 5 минут заработать достаточно донатов и купить эти предметы (bottle и courier)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заменили пропуски на нули с помощью функции fillna():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, что в столбцах больше нет пропусков:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество столбцов, в которых пропущены данные: \n",
      " 0\n"
     ]
    }
   ],
   "source": [
    "С = features.count()\n",
    "lose = С[С < 97230]\n",
    "print('Количество столбцов, в которых пропущены данные:','\\n',len(lose))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того чтобы обучение проходило быстрее, возьмем только половину данных из нашей выборки в случайном порядке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_d = features.take(np.random.permutation(len(features))[:int((len(features))/2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Целевая переменная хранится в колонке \"radiant_win\" (значения в ней: 1, если победила команда Radiant, 0 — иначе), перепишем её как отдельный столбец, а затем удалим из исходных данных, также удалим все стлбцы, которые содержат в себе информацию, которая выходит за рамки 5 минут матча. \n",
    "\n",
    "Вектор ответов обозначим за T (target)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = features_d['radiant_win'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ANACONDA\\lib\\site-packages\\pandas\\core\\frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "features_d.drop(['duration', 'radiant_win', 'tower_status_radiant', 'tower_status_dire', 'barracks_status_radiant', 'barracks_status_dire'], axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь признаки для обучения представлены в переменной features, а целевая переменная в переменной T. Таким образом, мы подготовили обучающую выборку и можем начинать применять к данным методы машинного обучения. Решение проведем в два этапа - с помощью градиентного бустинга и логистической регрессии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подход 1: градиентный бустинг \"в лоб\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод градиентного бустинга последовательно строит композицию алгоритмов, причем каждый следующий алгоритм выбирается так, чтобы исправлять ошибки уже имеющейся композиции. Обычно в качестве базовых алгоритмов используют деревья небольшой глубины, поскольку их достаточно легко строить, и при этом они дают нелинейные разделяющие поверхности.\n",
    "\n",
    "Забудем, что в выборке есть категориальные признаки, и попробуем обучить градиентный бустинг над деревьями на имеющейся матрице \"объекты-признаки\". Зафиксируем генератор разбиений для кросс-валидации по 5 блокам (KFold), не забыв перемешать при этом выборку (shuffle=True), поскольку данные в таблице отсортированы по времени, и без перемешивания можно столкнуться с нежелательными эффектами при оценивании качества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "parametrs = [10, 20, 30]\n",
    "Q = []\n",
    "time = []\n",
    "for n in parametrs:\n",
    "    array = 0\n",
    "    tmp = 0\n",
    "    clf = GradientBoostingClassifier(n_estimators=n, learning_rate=0.3)\n",
    "    clf.fit(features_d, T)\n",
    "    start_time = 0\n",
    "    start_time = datetime.datetime.now()\n",
    "    array = cross_val_score(estimator=clf, X=features_d, y=T, cv=kf, scoring='roc_auc')\n",
    "    m = np.mean(array)\n",
    "    tmp = datetime.datetime.now() - start_time\n",
    "    time.append(tmp)\n",
    "    Q.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время кросс-валидации для градиентного бустинга с 30 деревьями:\n",
      "0:02:17.046226\n"
     ]
    }
   ],
   "source": [
    "print('Время кросс-валидации для градиентного бустинга с 30 деревьями:')\n",
    "print(time[len(time) - 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество обучения алгоритма градиентного бустинга с 30 деревьями по  метрике AUC-ROC:\n",
      "0.6993932333836826\n"
     ]
    }
   ],
   "source": [
    "print('Качество обучения алгоритма градиентного бустинга с 30 деревьями по  метрике AUC-ROC:')\n",
    "print(Q[len(Q) - 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если посмотреть на значения качества алгоритма для 10, 20 деревьев и сравнить с качеством для алгоритма для 30 деревьев, то можно увидеть, что с увеличение качество улучшается все меньше и меньше. То есть в определнный момент наблюдается ассимптотический рост. Иначе говоря, обучать алгоритм более, чем с 30 деревьями будет иметь смысл только в том случае, если значения точности обучения важно вплоть до конкретного знака после запятой(сотая или тысячная доли). При этом будет наблюдаться увеличение времени обучения.\n",
    "Чтобы ускорить обучение алгоритма при увеличении количества деревьев можно предложить менять параметр learning rate, меняющий шаг градиентного спуска(learning_rate) или глубину деревьев(max_depth)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подход 2: логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линейные методы работают гораздо быстрее композиций деревьев, поэтому кажется разумным воспользоваться именно ими для ускорения анализа данных. Одним из наиболее распространенных методов для классификации является логистическая регрессия.\n",
    "\n",
    "Логистическая регрессия — один из видов линейных классификаторов. Одной из ее особенностей является возможность оценивания вероятностей классов, тогда как большинство линейных классификаторов могут выдавать только номера классов.\n",
    "\n",
    "Оценим качество логистической регрессии с L2-регуляризацией с помощью кросс-валидации по той же схеме, которая использовалась для градиентного бустинга. Подберем при этом лучший параметр регуляризации (C), помня при этом, что линейные алгоритмы чувствительны к масштабу признаков, то есть предварительно отмасштабируем признаки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = StandardScaler()\n",
    "feat_scl = scale.fit_transform(features_d)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "parametrs2 = [0.01, 0.1, 1, 10, 100, 10000]\n",
    "Q2 = []\n",
    "time2 = []\n",
    "for с in parametrs2:\n",
    "    array = 0\n",
    "    tmp = 0\n",
    "    clf2 = LogisticRegression(penalty='l2', C=с)\n",
    "    clf2.fit(feat_scl, T)\n",
    "    start_time = 0\n",
    "    start_time = datetime.datetime.now()\n",
    "    array = cross_val_score(estimator=clf2, X=feat_scl, y=T, cv=kf, scoring='roc_auc')\n",
    "    m = np.mean(array)\n",
    "    tmp = datetime.datetime.now() - start_time\n",
    "    time2.append(tmp)\n",
    "    Q2.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7153316839647503 0.7152412874794838 0.7152258310693542 0.7152244594052032 0.7152243831343252 0.7152242222746709\n"
     ]
    }
   ],
   "source": [
    "print(*Q2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наилучшее качество получилось у алгоритма логистической регрессии с параметром С = 0.01. Оно принимает значение 0.7165421785434388."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время кросс-валидации для алгоритма с данным параметром:\n",
      "0:00:02.919192\n"
     ]
    }
   ],
   "source": [
    "print('Время кросс-валидации для алгоритма с данным параметром:')\n",
    "print(time2[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заметим, что в данном случае качество логистической регрессии с масштабированными признаками на входе оказалось выше, чем качество градиентного бустинга (0.72 и 0.70 соответственно). Можно сказать, что алгоритмы дают одинаковое качество с точностью до второго знака после запятой, однако для алгоритма логистической регрессии необходимо провести тщательную предобработку данных. Это также говорит о достаточной степени независимости в наблюдаемых данных. При этом, время кросс-валидации логистической регресси гораздо меньше времени кросс-валидации градиентного бустинга (соответственно, время обучения также меньше)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Среди признаков в выборке есть категориальные, которые мы использовали как числовые, что вряд ли является хорошей идеей. Категориальных признаков в этой задаче одиннадцать: lobby_type и r1_hero, r2_hero, ..., r5_hero, d1_hero, d2_hero, ..., d5_hero. Уберем их из выборки, и проведем кросс-валидацию для логистической регрессии на новой выборке с подбором лучшего параметра регуляризации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ANACONDA\\lib\\site-packages\\pandas\\core\\frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "features_d.drop(['lobby_type', 'r1_hero', 'r2_hero', 'r3_hero', 'r4_hero', 'r5_hero', 'd1_hero', 'd2_hero', 'd3_hero', 'd4_hero' ,'d5_hero'],axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale2 = StandardScaler()\n",
    "feat_scl2 = scale.fit_transform(features_d)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "Q2 = []\n",
    "time2 = []\n",
    "for c in parametrs2:\n",
    "    array = 0\n",
    "    tmp = 0\n",
    "    clf2 = LogisticRegression(penalty='l2', C=c)\n",
    "    clf2.fit(feat_scl, T)\n",
    "    start_time = 0\n",
    "    start_time = datetime.datetime.now()\n",
    "    array = cross_val_score(estimator=clf2, X=feat_scl2, y=T, cv=kf, scoring='roc_auc')\n",
    "    m = np.mean(array)\n",
    "    tmp = datetime.datetime.now() - start_time\n",
    "    time2.append(tmp)\n",
    "    Q2.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7155367188626645 0.715459320222543 0.7154491098521729 0.7154456625293749 0.7154457644422798 0.7154457898078512\n"
     ]
    }
   ],
   "source": [
    "print(*Q2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наилучшее качество алгоритма опять было получено с параметром С = 0.01. Стоит правда отметить, что качество алгоритма после удаления категориальных признаков немного увеличилось. Несущественно (в четвертом знаке после запятой), но все же увеличилось. Скорее всего это произошло из-за того, что эти данные были избыточны и приводили к \"путанице\" алгоритма при обучении (происходила переподгонка)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На предыдущем шаге мы исключили из выборки признаки rM_hero и dM_hero, которые показывают, какие именно герои играли за каждую команду. Это важные признаки — герои имеют разные характеристики, и некоторые из них выигрывают чаще, чем другие. Выясним из данных, сколько различных идентификаторов героев существует в данной игре (используем фукнцию unique)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число различных идентификаторов:  108\n"
     ]
    }
   ],
   "source": [
    "N = np.array(features['r1_hero'])\n",
    "H = np.unique(N)\n",
    "print('Число различных идентификаторов: ', len(H))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуемся подходом \"мешок слов\" для кодирования информации о героях. Пусть всего в игре имеет N различных героев. Сформируем N признаков, при этом i-й будет равен нулю, если i-й герой не участвовал в матче; единице, если i-й герой играл за команду Radiant; минус единице, если i-й герой играл за команду Dire. Добавим полученные признаки к числовым, которые были использованы во втором пункте данного этапа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "hero_c = [c for c in features.columns if 'hero' in c]\n",
    "all_heroes_id = np.unique(features[hero_c])\n",
    "wb = {}\n",
    "for id in all_heroes_id:\n",
    "    r = [(features['r%d_hero' % n] == id) + 0 for n in range(1, 6)]\n",
    "    d = [(features['d%d_hero' % n] == id) + 0 for n in range(1, 6)]\n",
    "    wb['hero%s' % id] = sum(r) - sum(d)\n",
    "X_pick = features.assign(**wb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь вновь сократим данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ANACONDA\\lib\\site-packages\\pandas\\core\\frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "features_pick = X_pick.take(np.random.permutation(len(features))[:int((len(features))/2)])\n",
    "T2 = features_pick['radiant_win'].values\n",
    "features_pick.drop(['duration', 'radiant_win', 'tower_status_radiant', 'tower_status_dire', 'barracks_status_radiant', 'barracks_status_dire'], axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем кросс-валидацию для логистической регрессии на новой выборке с подбором лучшего параметра регуляризации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale3 = StandardScaler()\n",
    "feat_scl3 = scale.fit_transform(features_pick)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "Q3 = []\n",
    "time2 = []\n",
    "for c in parametrs2:\n",
    "    array = 0\n",
    "    tmp = 0\n",
    "    clf3 = LogisticRegression(penalty='l2', C=c)\n",
    "    clf3.fit(feat_scl3, T2)\n",
    "    start_time = 0\n",
    "    start_time = datetime.datetime.now()\n",
    "    array = cross_val_score(estimator=clf3, X=feat_scl3, y=T2, cv=kf, scoring='roc_auc')\n",
    "    m = np.mean(array)\n",
    "    tmp = datetime.datetime.now() - start_time\n",
    "    time2.append(tmp)\n",
    "    Q3.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7463087295698905 0.7462360157287664 0.7462213960690445 0.7462201915633251 0.746220175061526 0.7462203356241887\n"
     ]
    }
   ],
   "source": [
    "print(*Q3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наилучшее качество алгоритма снова было получено с параметром С = 0.01 (Значение 0.75). Стоит также отметить, что качество алгоритма увеличилось почти на 0.4. Это говорит о том, что информация о героях является важным признаком и при правильной кодировке его можно использовать для повышения качества алгоритма."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3 = LogisticRegression(penalty='l2', C=0.01)\n",
    "clf3.fit(feat_scl3, T2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тестирование алгоритма"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим предсказания вероятностей победы команды Radiant для тестовой выборки с помощью модели логистической регрессии (она оказалась лучшей с точки зрения AUC-ROC на кросс-валидации).\n",
    "\n",
    "Сначала загрузим тестовую выборку и произведем её предобработку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test = pd.read_csv('./features_test.csv', index_col='match_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test.fillna(0, inplace = True)\n",
    "hero_c = [c for c in features_test.columns if 'hero' in c]\n",
    "all_heroes_id = np.unique(features[hero_c])\n",
    "wb = {}\n",
    "for id in all_heroes_id:\n",
    "    r = [(features_test['r%d_hero' % n] == id) + 0 for n in range(1, 6)]\n",
    "    d = [(features_test['d%d_hero' % n] == id) + 0 for n in range(1, 6)]\n",
    "    wb['hero%s' % id] = sum(r) - sum(d)\n",
    "X_pick_test = features_test.assign(**wb)\n",
    "feat_scl_test = scale.transform(X_pick_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь произведем тестирование модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = clf3.predict_proba(feat_scl_test)\n",
    "predict_win_of_Radiant = []\n",
    "for now in predict:\n",
    "    predict_win_of_Radiant.append(now[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Минимальное и максимальное значение прогноза на тестовой выборке получилось у лучшего из алгоритмов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Минимальное значение прогноза:  0.010044047921850357\n",
      "Максимальное значение прогноза:  0.9959494389036317\n"
     ]
    }
   ],
   "source": [
    "print('Минимальное значение прогноза: ', min(predict_win_of_Radiant))\n",
    "print('Максимальное значение прогноза: ', max(predict_win_of_Radiant))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ВЫВОД:\n",
    "\n",
    "В данной работе проверялись два подхода для создания модели предсказания победителя оналйн-игры Dota 2. В результате, было выяснено, что модель логистической регрессии показала лучшее значение качества лучшей с точки зрения AUC-ROC на кросс-валидации, чем градиентный бустинг. Также процесс обучения и проверки качества занял гораздо меньше времени. Однако, стоит отметить, что линейная регрессия требовала гораздо более глубокой предобработки данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P.S. Спасибо за то, что нашли время и проверили мою работу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
